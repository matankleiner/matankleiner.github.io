<!DOCTYPE html>
<html dir="ltr" lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="Matan Kleiner">
  <meta name="description" content="Matan Kleiner's personal website">
  <meta name="keywords" content="Matan Kleiner, Technion, Optics, Deep Optics, Computational Imaging, Computer Vision, Deep Learning, Machine Learning, Generative Models">
  <title>Matan Kleiner</title>
  
  <link rel="icon" type="image/x-icon" href="./favicon.ico" />
  <link rel="icon"  href="assets/icons8-shutter-lineal-32.png">    
  <link rel="manifest" href="/site.webmanifest">
  
  <link rel="stylesheet" href="style.css">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
  <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">



    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300..800;1,300..800&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
  
    <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
 
    
</head>
<body>
<!--     <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL" crossorigin="anonymous"></script> -->
    <!--<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.8/dist/umd/popper.min.js" integrity="sha384-I7E8VVD/ismYTF4hNIPjVp/Zjvgyol6VFvRkX/vR+Vc4jQkC+hVqc2pM8ODewa9r" crossorigin="anonymous"></script>-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.min.js" integrity="sha384-BBtl+eGJRgqQAUMxJ7pMwbEyER4l1g+O15P+16Ep7Q9Q+zqX6gSbd85u4mG4QzX+" crossorigin="anonymous"></script>
  
  <div id="main" data-bs-spy="scroll" data-bs-target="#navbar" data-bs-offset="0" >
	<!-- Navbar -->
    <nav class="navbar sticky-top navbar-expand-md navbar-light bg-light shadow poppins-medium" id="navbar">
        <div class="container-xl">
            <a class="navbar-brand" href="#main">Matan Kleiner</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#main_nav">
                <span class="navbar-toggler-icon">
                    <!-- <i class="fa-duotone fa-bars"></i> -->
                </span>
            </button>
            <div class="collapse navbar-collapse" id="main_nav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="#home">Home</a></li>
                    <li class="nav-item"><a class="nav-link" href="#publications">Publications</a></li>
                    <!-- <li class="nav-item p-teaching"><a class="nav-link" href="#teaching">Teaching</a></li> -->
                </ul>
            </div> 
        </div> 
    </nav>

    <!-- Home Section -->

    <div id="home" class="bg-light section anchor" style="padding-top:20px"> 
        <div class="container-md" style="max-width:900px">
            <!-- Image on left and text on right -->
            <div class="row">
                <div class="col-md-4" style="display: flex; align-items: center;">
                    <img src="assets/prof_pic.jpg" class="img-fluid img-thumbnail rounded-circle" alt="Matan Kleiner">
                </div>
                <div class="col-md-8">
                    <h1 class="display-4">Matan Kleiner</h1>
                    <!-- <p class="lead">PhD Candidate at the Technion </p> -->
                    <p>I am a PhD candidate at the <a href="https://ece.technion.ac.il/" target="_blank">Electrical and Computer Engineering department</a>
                        of the <a href="https://www.technion.ac.il/en/home-2/" target="_blank">Technion</a>, 
                        under the supervission of <a href="https://tomer.net.technion.ac.il/" target="_blank"> Prof. Tomer Michaeli</a>.</p>
                    <p>My research interests lie at the intersection of optics, computational imaging, computer vision and deep learning.
                        I am exploring various theoretical aspects of optical computing, a promising paradigm that combines deep learning and photonics. 
                        Additionally, I am interested in the imaging pipeline, from accurately capturing objects in the physical world as images and videos to 
                        editing and manipulating them using vision foundation models.</p> 
                    <p>Contact me at <code style="color: rgb(0, 132, 255);">matan dot kleiner at campus dot technion dot ac dot il</code>.</p>
                    <p class="text-center">
                        <a href="https://github.com/matankleiner"><i class="fa fa-github fa-2x" aria-hidden="true"></i></a>
                        &nbsp;
                        <a href="https://scholar.google.com/citations?user=n3R271gAAAAJ&hl=en"><i class="ai ai-google-scholar ai-2x " aria-hidden="true"></i></a>
                        &nbsp;
			<a href="https://www.semanticscholar.org/author/Matan-Kleiner/2192821692"><i class="ai ai-semantic-scholar ai-2x " aria-hidden="true"></i></a>
                        &nbsp;
                        <a href="https://www.linkedin.com/in/matan-kleiner/"><i class="fa fa-linkedin-square fa-2x" aria-hidden="true"></i></a>
                        &nbsp;
                        <a href="https://x.com/MatanKleiner"><i class="fa fa-twitter fa-2x" aria-hidden="true"></i></a>
                    </p>
                </div>
            </div>
        </div>
    </div>
   
    <!-- Publications Section -->
    <div id="publications" class="bg-gray section anchor">
        <div class="subtlecircle sectiondivider faicon">
            <span class="fa-stack">
              <i class="fa fa-circle fa-stack-2x"></i>
              <i class="fa fa-file-text fa-stack-1x p-publications"></i>
            </span>
        </div>
        <h5 class="scetion-title text-center p-publications poppins-medium">Publications</h5>
  
        <div class="container" style="max-width: 1000px;">

            <div class="card mb-3 shadow anchor" id="Coherence Aware">
                <div class="card-body">
                    <div class="row open-sans-300">
                        <div class="col"><h5 class="card-title">Coherence Awareness in Diffractive Neural Networks</h5></div>
                        <div class="col-auto">
                            <a href="https://onlinelibrary.wiley.com/doi/10.1002/lpor.202401299"><i class="fa fa-external-link fa-lg" aria-hidden="true"></i></a>
                            &nbsp;
                            <a href="https://github.com/matankleiner/Coherence-Awareness-in-Diffractive-Neural-Networks"><i class="fa fa-github fa-lg" aria-hidden="true"></i></a>
                            &nbsp;
                            <span class="badge bg-primary">Laser Photonics Rev. 2025</span>
                        </div>
                    </div>
                        <h6 class="card-subtitle mb-2 text-muted">
                        <b>Matan Kleiner</b>,
                        <a href="https://www.linkedin.com/in/lior-michaeli-62a24862/" target="_blank" rel="noopener noreferrer" class="text-muted">Lior Michaeli</a>,
                        <a href="https://tomer.net.technion.ac.il/" target="_blank" class="text-muted">Tomer Michaeli</a></h6>
                                      
                    <p class="card-text">
                        Diffractive neural networks are a promising framework for optical computing.  
                        In this work we illustrate that, as opposed to imaging systems, in diffractive networks the degree of spatial coherence has a dramatic effect. 
                        We show that when the spatial coherence length on the object is comparable to the minimal feature size preserved by the optical system, 
                        neither the incoherent nor the coherent extremes serve as acceptable approximations. 
                        Following this observation, we propose a general framework for training diffractive networks for any specified degree of spatial and temporal coherence. 
                        Our findings serve as a steppingstone toward adopting all-optical neural networks in real-world applications, leveraging nothing but natural light. 
                        </br>
                        <span style="color: rgb(255, 123, 0);">Presented as an <i>oral presentation</i> at CLEO 2024.</span>
                    </p>
                </div>
                <div class="row">
                    <img src="assets/CohAware.png" class="card-img-bottom" style="padding-left: 7rem; padding-right: 7rem; padding-bottom: 1rem;" alt="">
                </div>
            </div>


            <div class="card mb-3 shadow" id="FlowEdit">
                <div class="card-body">
                    <div class="row open-sans-300">
                        <div class="col"><h5 class="card-title">FlowEdit: Inversion-Free Text-Based Editing Using Pre-Trained Flow Models</h5></div>
                        <div class="col-auto">
                            <a href="https://matankleiner.github.io/flowedit/"><i class="fa fa-external-link fa-lg" aria-hidden="true"></i></a>
                            &nbsp;
                            <a href="https://github.com/fallenshock/FlowEdit"><i class="fa fa-github fa-lg" aria-hidden="true"></i></a>
			                 &nbsp;
                             <a href="https://huggingface.co/spaces/fallenshock/FlowEdit" style="text-decoration: none;">ðŸ¤—</a>
			                 &nbsp;
                            <span class="badge bg-primary"></span>
                        </div>
                    </div>
                    <h6 class="card-subtitle mb-2 text-muted">
                        <a href="https://www.linkedin.com/in/vladimir-kulikov/" target="_blank" rel="noopener noreferrer" class="text-muted">Vladimir Kulikov</a>,
                        <b>Matan Kleiner</b>,
                        <a href="https://inbarhub.github.io/www/" target="_blank" rel="noopener noreferrer" class="text-muted">Inbar Huberman-Spiegelglas</a>,
                        <a href="https://tomer.net.technion.ac.il/" target="_blank" class="text-muted">Tomer Michaeli</a></h6>
                            <p class="card-text">
                                We introduce FlowEdit, a text-based editing method for pre-trained T2I flow models, which is inversion-free, optimization-free and 
                                model agnostic. Our method constructs an ODE that directly maps between the source and target distributions (corresponding to the source 
                                and target text prompts) and achieves a lower transport cost than the inversion approach. This leads to state-of-the-art results, as we 
                                illustrate with Stable Diffusion 3 and FLUX.
                    </p>
                </div>
                <div class="row">
                    <img src="assets/FlowEdit.png" class="card-img-bottom" style="padding-left: 7rem; padding-right: 7rem;" alt="">
                </div>
            </div>


            
            <div class="card mb-3 shadow anchor" id="Slicedit">
                <div class="card-body">
                    <div class="row open-sans-300">
                        <div class="col"><h5 class="card-title">Slicedit: Zero-Shot Video Editing With Text-to-Image Diffusion Models Using Spatio-Temporal Slices</h5></div>
                        <div class="col-auto">
                            <a href="https://matankleiner.github.io/slicedit/"><i class="fa fa-external-link fa-lg" aria-hidden="true"></i></a>
                            &nbsp;
                            <a href="https://github.com/fallenshock/Slicedit"><i class="fa fa-github fa-lg" aria-hidden="true"></i></a>
                            &nbsp;
                            <span class="badge bg-primary">ICML 2024</span>
                        </div>
                    </div>
                        <h6 class="card-subtitle mb-2 text-muted">
                        <a href="https://www.linkedin.com/in/nathaniel-cohen-6032b7235/" target="_blank" rel="noopener noreferrer" class="text-muted">Nathaniel Cohen<sup>*</sup></a>,
                        <a href="https://www.linkedin.com/in/vladimir-kulikov/" target="_blank" rel="noopener noreferrer" class="text-muted">Vladimir Kulikov<sup>*</sup></a>,
                        <b>Matan Kleiner<sup>*</sup></b>,
                        <a href="https://inbarhub.github.io/www/" target="_blank" rel="noopener noreferrer" class="text-muted">Inbar Huberman-Spiegelglas</a>,
                        <a href="https://tomer.net.technion.ac.il/" target="_blank" class="text-muted">Tomer Michaeli</a></h6>
                                      
                    <p class="card-text">
                        We present Slicedit, a method for text-based video editing that utilizes a pre-trained T2I diffusion model and spatiotemporal slices. 
                        Spatiotemporal slices of natural videos exhibit similar characteristics to natural images. Therefore, the same T2I diffusion model
                        that is normally used only as a prior on video frames can also serve as a strong prior for enhancing temporal consistency by applying 
                        it on spatiotemporal slices. 
                        Slicedit generates videos that retain the structure and motion of the original video while adhering to the 
                        target text. It edit a wide range of real-world videos, including videos with strong nonrigid motion and occlusions.
                        </br>
                        <span style="color: rgb(255, 123, 0);">Presented as an <i>oral presentation</i> at the CVG workshop @ ICML 2024.</span>
                    </p>
                </div>
                <div class="row">
                    <img src="assets/Slicedit.png" class="card-img-bottom" style="padding-left: 7rem; padding-right: 7rem;" alt="">
                </div>
            </div>

            <div class="card mb-3 shadow anchor" id="SinDDM">
                <div class="card-body">
                    <div class="row open-sans-300">
                        <div class="col"><h5 class="card-title">SinDDM: A Single Image Denoising Diffusion Model</h5></div>
                        <div class="col-auto">
                            <a href="https://matankleiner.github.io/sinddm/"><i class="fa fa-external-link fa-lg" aria-hidden="true"></i></a>
                            &nbsp;
                            <a href="https://github.com/fallenshock/SinDDM"><i class="fa fa-github fa-lg" aria-hidden="true"></i></a>
                            &nbsp;
                            <span class="badge bg-primary">ICML 2023</span>
                        </div>
                    </div>
                        <h6 class="card-subtitle mb-2 text-muted">
                        <a href="https://www.linkedin.com/in/vladimir-kulikov/" target="_blank" rel="noopener noreferrer" class="text-muted">Vladimir Kulikov</a>,
                        <a href="https://www.linkedin.com/in/shahar-yadin-069725195/" target="_blank" rel="noopener noreferrer" class="text-muted">Shahar Yadin<sup>*</sup></a>,
                        <b>Matan Kleiner<sup>*</sup></b>,
                        <a href="https://tomer.net.technion.ac.il/" target="_blank" class="text-muted">Tomer Michaeli</a></h6>
                                      
                    <p class="card-text">
                        We introduce a framework for training a DDM on a single image, which we coin SinDDM.
                        SinDDM learns the internal statistics of the training image by using a multi-scale diffusion process and generate samples of arbitrary dimensions, 
                        in a coarse-to-fine manner. 
                        SinDDM generates diverse high-quality samples and it can be easily guided by external supervision, such as CLIP model.
                    </p>
                </div>
                <div class="row">
                    <img src="assets/sinddm.svg" class="card-img-bottom" style="padding-left: 7rem; padding-right: 7rem; padding-bottom: 1rem;" alt="">
                </div>
            </div>

        </div>
    </div>

    <!-- Footer -->
    <div id="footer" class="text-center text-bg-dark bg-dark">
      <div class="container-xl">	  
            Adapted from the personal webpage of <a class="text-white" href="https://hilamanor.github.io/">Hila Manor</a>, 2024
			&nbsp;|&nbsp;
			Icons from <a class="link-secondary" target="_blank" href="https://icons8.com">Icons8</a>, 
            <a class="link-secondary" href="http://fontawesome.io">Font Awesome</a> & <a class="link-secondary" href="https://jpswalsh.github.io/academicons">Academicons</a>
			<br>
            Parts of this webpage were based on Tim Oâ€™Brien's <a class="link-secondary" href="http://t413.com/">t413.com</a> 
            â€”
            <a class="link-secondary" href="https://github.com/t413/SinglePaged">SinglePaged theme</a>.
		
      </div>
    </div>
  </div>

</body>
</html>
